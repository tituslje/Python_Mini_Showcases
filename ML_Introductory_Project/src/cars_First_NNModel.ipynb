{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import itertools\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "print(physical_devices)\n",
    "\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download cars dataset and split into 3 datasets: training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://stanfordmedicine.box.com/shared/static/1onms226m6z9oyzsgqjn93h80rqyeqhq.zip \\-O /tmp/cars.zip\n",
    "\n",
    "local_zip = '/tmp/cars.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/tmp/cars'\n",
    "train_path = os.path.join(base_path, 'train')\n",
    "valid_path = os.path.join(base_path, 'valid')\n",
    "test_path = os.path.join(base_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['BMW','Bugatti','Lamborghini','McLaren','Volkswagen'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['BMW','Bugatti','Lamborghini','McLaren','Volkswagen'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['BMW','Bugatti','Lamborghini','McLaren','Volkswagen'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train NN Model, first few layers inspired from VGG-16 fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=(3,3),activation='relu',padding='same', input_shape=(224,224,3), kernel_regularizer = 'l2'),\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu',padding='same', kernel_regularizer = 'l2'),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Conv2D(filters=128,kernel_size=(3,3), activation='relu',padding='same', kernel_regularizer = 'l2'),\n",
    "    Conv2D(filters=128,kernel_size=(3,3), activation='relu',padding='same', kernel_regularizer = 'l2'),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=5,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#copy and paste this for regularization: kernel_regularizer = 'l2'\n",
    "\n",
    "#vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
    "#model = Sequential()\n",
    "#for layer in vgg16_model.layers[:-1]:\n",
    "#    model.add(layer)\n",
    "#\n",
    "#for layer in model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "#model.add(Dense(units=5, activation='softmax'))\n",
    "#model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=train_batches,validation_data=valid_batches,epochs=15,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Testing of fitted NN parameters using the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_batches.classes\n",
    "\n",
    "output_layer = model.predict(x=test_batches, verbose=0)\n",
    "np.round(output_layer)\n",
    "\n",
    "y_pred = np.argmax(output_layer, axis=-1)\n",
    "\n",
    "#Plot confusion matrix using test and prediction data\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['BMW','Bugatti','Lamborghini','McLaren','Volkswagen'])\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate metrics and plot validation error and training error to spot overfit possibility\n",
    "loss,acc = model.evaluate(x=test_batches)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(hist.history['loss'],label='Train Loss')\n",
    "plt.plot(hist.history['val_loss'], label='val loss')\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "#plt.xlim(0,10) #Adjust to any number suitable for plot\n",
    "#plt.ylim(0,1) #Adjust to any number suitable for plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model accuracy vs Training accuracy as a function of epochs\n",
    "\n",
    "plt.plot(hist.history['accuracy'],label='Train_Acc')\n",
    "plt.plot(hist.history['val_accuracy'],label='Val_Acc')\n",
    "plt.title('Training vs Validation Accuracies')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_CH4244",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
